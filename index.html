<!DOCTYPE html>
<html>

<head>
    <title>Web Engineering Seminar Summer Semester 2025 - Evaluating Knowledge Graphs : Quality and Validation</title>
    <link rel="stylesheet" type="text/css" href="main.css" />
    <link href='http://fonts.googleapis.com/css?family=Source+Serif+Pro:400,600,700' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Inconsolata:400,700' rel='stylesheet' type='text/css'>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
</head>

<body>
    <header>
        <h2>Web Engineering Seminar Summer Semester 2025</h2>
        <h1>Evaluating Knowledge Graphs: Quality and Validation</h1>
        <h2 class="author">Amami Uduwana <br> Pabasara Piyumali Palihena Mudiyanselage</h2>
        <h3 class="affiliation">
            Professorship for Distributed and Self-Organizing Computer Systems, <br />
            Chemnitz University of Technology<br />
            Chemnitz, Germany
        </h3>
    </header>
    <section>
        <h2>1. Introduction</h2>
        <p>
            In recent years the web has become more diverse with a growing volume of online content that contains
            machine readable metadata.
            The development of promising machine learning technologies can be used to easily extract the data existing
            in the internet<a href="#r1">[1]</a>.
            This has led to the emergence of the concept of Knowledge Graphs (KG). “Knowledge graph is a promising
            technique for storing and
            communicating real-world knowledge with nodes representing entities and edges representing relationships
            between entities”<a href="#r2">[2]</a>.
        </p>
        <p>
            Knowledge Graphs can be categories in to open and proprietary types. Open KGs like DBpeida, Wikidata,
            Freebase,
            YAGO and NELL are publicly accessible and widely used in current research context and Proprietary KGs like
            Facebook’s
            Entities Graph, Google’s Knowledge Graph and Cyc are developed by companies to enhance their own
            applications and services <a href="#r3">[3]</a>.
        </p>
        <p>
            The importance of KGs lies in their ability to provide context, connect disparate data sources, and enable
            advanced analytical
            capabilities <a href="#r7">[7]</a>.As a result, KGs have been widely used in several real-world applications
            like personalized recommendation
            systems, exploratory search <a href="#r4">[4],</a><a href="#r5">[5],</a><a href="#r6">[6]</a> and
            domain-specific tasks including healthcare analytics, tourism,
            education and
            production and manufacturing <a href="#r8">[8]</a>.It is evident from these applications that KGs are
            essential for delivering structured and
            semantically rich data <a href="#r9">[9]</a>.
        </p>
    </section>
    <section>
        <h2> 2. Knowledge Graph Quality Control</h2>
        <!--<h3> 2.1. Allgemeiner Überblick </h3>-->

        <p>
            Despite their usages, KGs give rise to quality concerns which may limit their performance in practical
            applications.
            Regardless of the type or number of sources used to generate a knowledge graph, the initial data is often
            incomplete,
            contains duplicates, inconsistent, or even error prone particularly when information is gathered from
            multiple sources <a href="#r9">[9]</a>.
            As a result, assessing the quality of the generated KG is a crucial step in quality control <a
                href="#r11">[11]</a>. The quality of KGs
            defined as the fitness for purpose and quality assessment helps to determine for which purpose a KG can be
            reliably used <a href="#r10">[10]</a>.
            This process of ensuring and improving the quality of KGs are known as Knowledge Curation (aka Knowledge
            Refinement) <a href="#r13">[13]</a>.
        </p>
        <p>
            Six principle dimensions have been introduced to assess the KG quality: accuracy, consistency, completeness,
            timeliness,
            trustworthiness, and availability <a href="#r11">[11]</a>. Each of these dimensions is interrelated and
            understanding their relationship helps
            to select the suitable validation method tailored to different application needs. The current research
            defines that ensuring
            the high-quality KGs involves not only their initial KG construction, but also the ongoing maintenance and
            enhancement as new
            data and application requirements emerge <a href="#r12">[12]</a>.
        </p>
        <p>
            This study focuses on examining quality indicators such as accuracy, consistency, completeness, and
            redundancy.
            The evaluation methodologies identified for each indicator were thoroughly tested on a manually created
            domain
            specific knowledge base, to assess their effectiveness and operational performance.
        </p>

        <h3> 2.1. Accuracy in Knowledge Graphs </h3>

        <p>
            Accuracy in KGs relates to how faithfully the graph's facts or statements
            (usually represented as triples: subject, predicate, object) reflect real-world information <a
                href="#r14">[14]</a>.
            It is the most important dimension of KG quality. The primary factors that degrade KG accuracy are incorrect
            relations,
            incorrect entities, and incorrect attributes in the KG. Therefore, appropriate validation methods must be
            performed to detect
            such errors and enhance the accuracy of the KG <a href="#r11">[11]</a>.
        </p>
        <p>
            KG accuracy has often been discussed in other literature. For Example <a href="#r15">[15]</a> defines KG
            accuracy as
            “the extent to which knowledge are correct, reliable, and certified free of error”. Some studies consider
            the accuracy of knowledge as a synonym for knowledge quality <a href="#r16">[16]</a>.
        </p>

        <h3> 2.2. Consistency in Knowledge Graphs</h3>
        <p>
            In recent research <a href="#r11">[11]</a> “KG consistency is defined as the degree to which the knowledge
            of a KG does not contradict itself”.
            Consistency focused on logical correctness of KGs rather than the semantic correctness of triples <a
                href="#r7">[7],</a> <a href="#r17">[17]</a>.
            Our KG contains
            the following triples <i>[James Potter, IsFatherOf, Harry Potter], [James Potter, IsHusbandOf, Lily
                Potter]</i>, and
            <i> [Lily Potter, IsSisterOf, Harry Potter]</i>. Looking at the first two triples we can conclude that Lily
            is Harry’s mother.
            However, the third triple <i> [Lily Potter, IsSisterOf, Harry Potter] </i> introduces a sibling
            relationship, which contradicts the
            assumed parent-child relationship. This semantic contradiction makes the knowledge graph logically
            inconsistent.
        </p>

        <figure>
            <img src="figure01.png" alt="Consistency Example" />
            <figcaption>
                <strong>Figure 01</strong>: Example of Logical Inconsistency
            </figcaption>
        </figure>

        <h3> 2.3. Building and Validating a Domain-Specific KG: A Harry Potter Case Study</h3>
        <p>
            Generally, accuracy and consistency in KGs can be detected through several validation methods. To
            demonstrate
            practical application of those techniques, we constructed simple yet high quality KG based on the Harry
            Potter universe.
            The graph structure and entity relationships were initially conceptualized by referring the most common
            facts about this
            universe. The formal ontology creation, modeling of the KG, and validation were performed using the Protégé,
            a free and
            user-friendly ontology editor for KGs. This method ensures that our KG adheres to semantic web standards and
            supports
            various validation methods that we apply to assess different quality metrics of KGs.
        </p>
        <figure>
            <img src="figure02.png" alt="KG Creation " />
            <figcaption>
                <strong>Figure 02</strong>: KG Creation Workflow
            </figcaption>
        </figure>

        <h2> 3. State-of-the-Art Methods for KG Validation</h2>

        <p>Generally, accuracy and consistency in KGs can be detected through several validation methods. </p>

        <h3>3.1. Manual Ground Truth validation.</h3>

        <p>
            Researchers relies on human experts to manually verify the correctness of each triples within a KG. This is
            the most reliable way to find the truthfulness of facts in the KG. However modern KGs can contain millions
            or even
            billions of triples, making manually checking each triple is impractical and expensive in the terms of time
            and resources <a href="#r14">[14]</a>.
        </p>
        <p>
            To address this challenge the researchers manually annotate only a small and randomly selected sample
            triples. This subset is used
            to measure the overall accuracy of the entire KG. If the sample size is too small, the resulting accuracy
            may not reflect the true
            accuracy of the entire KG, leading to potential errors. A sufficiently enough sample size is required to
            obtain a statistically
            relevant estimate, though this increases both the cost and time required for manual annotation <a
                href="#r14">[14]</a>.
        </p>

        <h3> 3.2. Crowdsourcing</h3>
        <p>
            Crowdsourcing is a promising method for building and verifying a high-quality knowledge graph from the
            knowledge of
            many casual users not just experts. Two primary tasks in this method are Knowledge collection and
            verification.
            Collection involves gathering facts from a large number of users through fill in the blank quizzes while
            verification
            ensures the correctness of those facts through true or false quizzes. This approach not only engages users
            but also ensures
            that both collection and verification are carried out efficiently <a href="#r1">[1]</a>
        </p>

        <p>
            Such manual validation methods are time consuming and expensive therefore only a small, randomly samples
            subset of
            triples is typically checked by experts. Crowdsourcing allows for the validation of a much larger set of
            facts by
            distributing the work among many users and helps maintain the accuracy and consistency of the KG while
            reducing the
            burden on individual curators <a href="#r1">[1],</a> <a href="#r18">[18],</a> <a href="#r19">[19]</a>.
        </p>

        <h3> 3.3. Human in the Loop Validation </h3>
        <p>
            Human-in-the-loop (HITL) validation refers to the process of involving human experts in the KG validation
            process
            alongside automated validation methods such as those based on Large Language Models (LLMs) <a
                href="#r23">[23]</a>. With large KGs,
            fully automated techniques may overlook subtle errors and require domain-specific expertise, especially when
            dealing
            with context-specific or ambiguous scenarios <a href="#r24">[24]</a>.
        </p>
        <p>
            For instance, our KG contains two distinct nodes representing the characters<i>Tom Riddle and Lord Voldemort
            </i>.
            Due to shared facts such as wand core, school, house, mother, and language ability, automated tools may flag
            these nodes as potential duplicates. However, based on domain knowledge, experts can confirm that these two
            nodes actually refer to the same individual. In such cases HITL validation becomes essential for resolving
            ambiguities that automated methods alone cannot address.
        </p>

        <h3> 3.4. Rule Based Validation using SPARQL</h3>
        <p>
            Rule-based validation is essential for maintaining the accuracy and consistency of KGs. SPARQL, the
            standardized query
            language for RDF recommended by the W3C, is widely used for this purpose <a href="#r2">[2]</a>. Ontology
            management tools like Protégé
            supports the modeling and storage of KGs in formats like RDF or TTL <a href="#r20">[20]</a>. Competency
            questions, which define the requirements
            for the KG are first formulated in natural language and then translated into SPARQL queries. Once queries
            are formed, we can
            use them to execute against the KG to validate it’s structure and content. For instance, a properly
            constructed SPARQL query
            can check if all instances of a class have required properties, or if there are any logical contradictions
            <a href="#r7">[7]</a>.
        </p>
        <p>
            A SPARQL constraint was implemented to ensure that no character could be both academic
            staff and a student simultaneously. The query was implemented within the Protégé SPARQL editor as follows;
        </p>


        <figure>
            <img src="query01.png" alt="Query 01" />
            <figcaption>
                <strong>Query 01</strong>: Select every character that has been incorrectly assigned to both the
                academic staff (hp:AcademicStaff) and student (hp:Student) roles at the same time.
            </figcaption>
        </figure>



        <p> Another SPARQL constraint was used to validate that each character is assigned one blood status at a time.
        </p>
        <figure>
            <img src="query02.png" alt="Query 02" />
            <figcaption>
                <strong>Query 02</strong>: The query groups characters by their identifier and counts how many blood
                statuses (hp:hasBloodStatus) are assigned to each one. It returns only characters who have been assigned
                more than one blood status are returned.
            </figcaption>
        </figure>

        <h3>3.5. Schema Based Validation using SHACL </h3>
        <p> Shapes Constraint Language (SHACL) is a W3C-recommendation for defining constraints over RDF data <a
                href="#r3">[3]</a>.
            Quality metrics such as accuracy and consistency can be ensured by using SHACL as a validation language.
            SHACL enables schema like structures known as shapes to validate a KG. Through the application of these
            shapes,
            large volumes of data can be filtered and validated, thereby enhancing the overall quality of the KG <a
                href="#r21">[21]</a>.</p>

        <p> The SHACL Core Vocabulary distinguishes between two main types of shapes as node shapes and property shapes
            <a href="#r24">[24]</a>.
            Node shapes are applied to a set of nodes within an RDF data graph, referred to as focus nodes. Property
            shapes, on
            the other hand, validate the values of particular properties associated with these focus nodes <a
                href="#r24">[24]</a>.
            Target specifications are used to define which nodes in the RDF graph are selected <a href="#r3">[3],</a> <a
                href="#r22">[22].</a></p>

                <p> To demonstrate SHACL validation we created several SHACL shapes that ensures the accuracy and 
                    consistency of our KG based on Harry Potter Universe.</p>

                    <figure>
            <img src="shape01.png" alt="Shape 01" />
            <figcaption>
                <strong>SHACL Shape 01 </strong>: Character must belong to one of the known houses
            </figcaption>
        </figure>

        <p>
            This validation rule applies to all instances of the hp:Character class in ourKG. It checks the 
            property hp:belongsToHouse for each character to ensure that its value is one of the four houses 
            listed in the SHACL shape. If this condition is not met, the validation process will report an error with the 
            specified message in the validation report.
        </p>
 <figure>
            <img src="shape 02.png" alt="Shape 02" />
            <figcaption>
                <strong>SHACL Shape 02 </strong>: Hermione Granger must belong to the house of Gryffindor
            </figcaption>
        </figure>

        <p>
            This SHACL shape targets the node of Hermione Granger (hp:HermioneGranger) and checks the property hp:belongsToHouse 
            for Hermione Granger has the value hp:Gryffindor. If this condition is not met, the validation process will report 
            an error with the specified message in the validation report.
        </p>


        <figure>
            <pre>
function createAndSendDocument() {
  // Create a new Google Doc named 'Hello, world!'
  var doc = DocumentApp.create('Hello, world!');Abbildung

  // Access the body of the document, then add a paragraph.
  doc.getBody().appendParagraph('This document was created ');

  // Get the URL of the document.
  var url = doc.getUrl();

  // Get the email address of the active user - that's you.
  var email = Session.getActiveUser().getEmail();

  // Get the name of the document to use as an email subject line.
  var subject = doc.getName();

  // Append a new string to the "url" variable to use as an email.
  var body = 'Link to your doc: ' + url;

  // Send yourself an email with a link to the document.
  GmailApp.sendEmail(email, subject, body);
}
        </pre>
            <figcaption>
                <strong>Listing 1</strong>: Beispiel Google Script: Spreadsheet erstellen und Link per Mail senden <a
                    href="#r7">[7]</a>

            </figcaption>
        </figure>
    </section>
    <section>
        <h3>2.2. Datenschutz und -sicherheit</h3>
        <p>
            Bei solchen hohen Nutzerzahlen haben beide Anbieter eine große Verantwortung bezüglich der Sicherheit der
            Daten. Dazu zählen natürlich angemessene
            Datenschutzrichtlinien und Verschlüsselungstechniken, aber auch die Ermutigung und Aufklärung des Anwenders
            den eigenen Account so einbruchssicher wie
            möglich zu gestalten. Dies beginnt schon bei der Registrierung, nämlich mit der Festlegung eines starken
            Passworts.
        </p>
        <p>
            Beide Dienste weisen bei der Registrierung auf die Stärke des Passworts mit Hilfe eines Farbbalkens hin. Die
            Einstufung erhöht sich je länger die Eingabe
            wird und je mehr zwischen Groß- und Kleinschreibung, Zahlen und Sonderzeichen variiert wird <a
                href="#r3">[3]</a>. Zusätzlich wird von beiden die zweistufige Verifizierung stark
            empfohlen, bei der nicht nur Username und Passwort, sondern ein zusätzlicher Pin ans Handy gesendet wird, um
            sicherzustellen, dass es sich wirklich um
            den bestimmten Nutzer handelt. Aber auch hier unterscheiden sich Google und Dropbox in den Details der
            Umsetzung. Während Dropbox diesen Code entweder per SMS verschickt
            oder über eine App generieren lässt <a href="#r7">[7]</a>, bietet Google zusätzlich die Übermittlung per
            Sprachanruf und die Variante der Backup-Codes an <a href="#r8">[8]</a>. Letztere sind vor
            allem nützlich, wenn das Smartphone bzw. der Empfang gerade nicht zur Hand ist.
        </p>
        <p>
            Der nächste wichtige Sicherheitsaspekt ist die Übertragung der Daten. Diese findet bei beiden
            selbstverständlich über SSL/TSL und HTTPS statt. Danach
            findet die serverseitige Verschlüsselung über AES-256 bei Dropbox <a href="#r7">[7]</a> und AES-128 bei
            Google <a href="#r8">[8]</a> statt. Beide verschlüsseln die Daten
            jedoch mit eigenen generierten Schlüsseln, was zu der Kritik führt, dass „[s]ince Dropbox itself encrypts
            the data on the server-side, users cannot be sure
            by cryptographic means that all stored data is highly confidential“ <a href="#r3">[3]</a>. Über Google ist
            die Kritik sogar noch lauter, denn hier wird
            erst seit gut einem Jahr serverseitig verschlüsselt <a href="#r1">[1]</a>. Zuvor wiesen Mitarbeiter des
            GoogleDrive Team
            nur auf die sichere Kommunikation zwischen Server und Client hin bzw. machten auf den Gebrauch der
            zwei-Schritt-Verifizierung aufmerksam <a href="#r1">[1]</a>.
            Dass die Schlüssel jedoch selbst generiert und verwaltet werden, sorgt auch hier für Unwohlsein <a
                href="#r1">[1]</a>.
        </p>
        <p>
            Aus diesem Problem hat sich ein ganz eigener Markt entwickelt. Dropbox selbst weist in ihrem Helpcenter auf
            „zahlreiche Drittanbieter“ <a href="#r7">[7]</a>
            hin, mit Hilfe welcher Anwender ihre Daten selber verschlüsseln können, bevor sie diese in die Cloud
            hochladen. Auch Borgmann et al. kommen zu dem Schluss,
            dass es „a whole range of alternative methods“<a href="#r3">[3]</a> gibt, um die eigenen Daten schon lokal
            zu verschlüsseln und selber die Schlüssel zu verwalten. Einer
            dieser Anbieter ist Boxcryptor, 2011 gegründet und mit mittlerweile über 1 Millionen Downloads oft genutzt
            <a href="#r4">[4]</a>.
        </p>
        <p>
            Boxcryptor ist eine Anwendung die speziell zur Verschlüsselung von Daten, welche anschließend in der Cloud
            gespeichert werden sollen, entwickelt wurde. Das
            Prinzip ist recht simpel. Die zu verschlüsselnden Daten werden in einem entsprechenden Ordner auf einem
            virtuellen Laufwerk abgelegt und dort mit Hilfe der
            AES-256 und RSA Algorithmen verschlüsselt. Danach erst werden die Dateien in den Cloud Ordner weitergegeben.
            Verschlüsselte Daten sind farblich markiert
            und leicht von anderen, nicht verschlüsselten Daten, zu unterscheiden. Diese Software ist kompatibel mit
            allen großen Cloud Dienst Anbietern und allen Betriebssystemen. Auch für Android, iOS und
            Blackberry gibt es Apps, sodass hier ebenfalls keine Einschränkung besteht <a href="#r4">[4]</a>.
        </p>
    </section>
    <section>
        <h2>3. Alternativen</h2>
        <h3>3.1. BitTorrent Sync</h3>
        <p>
            Neben zusätzlichen Verschlüsselungssoftwares, die mit Cloud Diensten zusammen angewendet werden können,
            haben sich aber auch Dienste entwickelt, die auf
            Serverspeicherung gänzlich verzichten, und dennoch die gleichen Vorteile versprechen. Zwar noch in der Beta
            Phase, aber trotzdem ein vielversprechendes Konzept,
            präsentiert beispielsweise BitTorrent Sync. Hier werden Daten direkt zwischen Geräten synchronisiert. Dazu
            müssen diese in dem entsprechenden Sync Ordner
            abgelegt werden, woraufhin ein 20 Byte langer Geheimschlüssel generiert wird. Über diesen Schlüssel können
            anschließend andere Geräte auf
            diese Daten zugreifen. Dies ermöglicht ebenfalls das Teilen von Daten mit Dritten. Mit Hilfe drei
            verschiedener Einstufungen der Geheimschlüssel, auch <em>Secrets </em> genannt,
            ist es möglich, Berechtigungen zuzuschreiben und sogar ein zeitliches Limit des Teilens zu setzen <a
                href="#r2">[2]</a>.
        </p>
        <p>
            Ein entscheidender Vorteil ist, dass durch dieses Prinzip keine Einschränkung des zu verfügbaren
            Speicherplatzes seitens des Anbieters stattfindet. Dieser
            richtet sich nach der eigenen Kapazität. Außerdem entstehen keine Fragen bezüglich des Standortes der Server
            und damit folgenden unterschiedlichen
            Datenschutzrichtlinien, da die Daten nur auf den eigenen Geräten gespeichert werden. Gerade in Hinblick auf
            die Abhörskandale der NSA und auch des BND
            stößt dies auf große Begeisterung:
        </p>
        <p>
            „That difference in design means that people using Bittorrent Sync don’t have to worry about whether the
            cloud company hosting their data is properly
            securing it against rogue employees or other threats. Forgoing the cloud also means that data shared using
            Bittorrent Sync could be harvested by the NSA or
            another agency only by going directly to the person or company controlling the synced devices”<a
                href="#r11">[11]</a>.
        </p>
        <p>
            Die Kommunikation zwischen zwei Geräten ist über den AES-128 Algorithmus verschlüsselt. Zudem wird das P2P
            Protocol verwendet. Trotz Beta Phase
            erstreckt sich das Angebot der Desktop Version bereits über Windows, Mac und Linux, und auch die
            Unterstützung mobiler Geräte deckt Android, iOS, Windows
            Phone und den Kindle Fire ab <a href="#r2">[2]</a>.
        </p>
        <p>
            Ein für diese Technik spezifischer Nachteil ist allerdings die Voraussetzung, dass zur Synchronisation die
            entsprechenden Geräte angeschaltet sein müssen<a href="#r11">[11]</a>.
            Sollte die Verbindung zu einem Zeitpunkt der Übertragung abbrechen, wird diese jedoch an der entsprechenden
            Stelle wieder fortgesetzt, sobald
            beide Geräte wieder online sind<a href="#r6">[6]</a>.
        </p>
    </section>
    <section>
        <h3>3.2 ownCloud</h3>
        <p>
            Wer dennoch lieber eine Cloud zur Hand haben und trotzdem auf einen kommerziellen Anbieter verzichten
            möchte, hat die Möglichkeit mit ownCloud sich selber
            eine Cloud aufzusetzen. Zuerst vorgestellt in 2011, erfreut sich diese Software heute recht großer
            Beliebtheit. Nach eigenen Angaben nutzen mehr als 1,3 Millionen
            Anwender diesen Service <a href="#r10">[10]</a>. Und tatsächlich finden sich zahlreiche Anleitungen im
            Internet, wie man sich zu Hause mit Hilfe eines Raspberry Pis
            und ownCloud selber eine Cloud basteln kann <a href="#r12">[12]</a> <a href="#r9">[9]</a> <a
                href="#r5">[5]</a>.
        </p>
        <p>
            Die Vorteile sind schnell zusammengefasst: Erstens orientiert sich die Speicherkapazität, ebenso wie bei
            BitTorrent Sync, an den eigenen Gegebenheiten. Der
            Vorteil gegenüber dem Konzept von BitTorrent Sync ist allerdings, dass durch die Zwischenspeicherung der
            Daten, kein anderes Gerät als das auf dem die
            Daten gewollt sind online sein muss. Vor allem aber ist der Ort der gespeicherten Daten selbst bestimmt.
        </p>
        <p>
            Jedoch ganz ohne Schattenseite ist auch diese Alternative nicht. Gewisse Kenntnisse über Server, Netzwerke
            und Sicherheitsprotokolle sollten vorhanden sein
            <a href="#r5">[5]</a>. Zudem ist die Hochverfügbarkeit, wie sie bei Dropbox oder Google herrscht, nicht
            gewährt.
        </p>
    </section>
    <section>
        <h2>4. Demo ownCloud</h2>
        <h3>4.1. Das Set-Up</h3>
        <p>
            Die häufigste Empfehlung und einfachste Lösung für Privatpersonen ist die Nutzung eines Raspberry Pis auf
            dem Raspbian installiert ist <a href="#r12">[12]</a>. Bevor
            die eigentliche ownCloud installiert werden kann, bedarf es noch einiger Konfigurationen, wie zum Beispiel
            die Installation eines Apache Servers, PHP und
            SQL Datenbank <a href="#r9">[9]</a>. Für das Erreichen der Cloud innerhalb des Heimnetzwerks reicht dies
            schon, wenn man allerdings auch von außerhalb an die Cloud gelangen
            möchte, empfiehlt sich die Registrierung bei einem Dynamic DNS Dienst und die Installation dessen Clients
            zum regelmäßigen aktualisieren der IP Adresse.
        </p>
        <p>
            Anschließend kann die neuste Version von ownCloud heruntergeladen und installiert werden. Während des
            Installationsprozesses hat man die Möglichkeit
            entweder die IP des Raspberrys oder eine registrierte URL einzugeben, über welche die ownCloud dann
            erreichbar ist. Dazu sollten dann auch die Ports 80 und
            443 im Router zur Weiterleitung freigegeben sein<a href="#r9">[9]</a>.
        </p>
        <p>
            Der nächste Schritt ist bezüglich Sicherheit. Um eine sichere Verbindung über HTTPS zu haben, kann ein
            selbstsigniertes Zertifikat erzeugt werden. Zwar
            erscheint dann beim Aufruf der Seite die Warnung, dass es sich um keine vertrauenswürdige Verbindung
            handelt, jedoch ist der Grund dafür ja die selbst
            ausgestellte Signatur. Durch Hinzufügen einer Ausnahme für dieses Zertifikat und abspeichern im Browser ist
            dennoch eine gewisse Kontrolle über die
            Verbindung gewährt. Sollte in Zukunft beim Aufrufen der Seite diese Warnung wieder erscheinen, obwohl das
            eigene Zertifikat gespeichert wurde, weiß man
            beispielsweise, dass jemand Fremdes an dem Zertifikat Änderungen vorgenommen hat <a href="#r5">[5]</a>.
        </p>
        <p>
            Als letztes muss nun nur noch der Dynamic DNS Update Client installiert und konfiguriert werden. Nach einem
            Neustart des Servers und einloggen auf der
            eigenen ownCLoud über das Webinterface ist diese bereit zum Nutzen. Es können weitere Apps eingebunden, eine
            Synchronisation mit Adressbuch oder Kalender
            eingerichtet und das Aussehen angepasst werden <a href="#r10">[10]</a>.
        </p>
    </section>
    <section>
        <h3>4.2. Funktionsbeispiele</h3>

        <p>
            Ein sehr positiver Aspekt ist, dass man die eigene Cloud auch anderen zugänglich machen kann. Der Admin kann
            Benutzer anlegen und diese Gruppen sowie
            Rechte zuweisen (siehe Abb.1). Diese können ihre eigenen Daten hochladen, verwalten, teilen und miteinander
            interagieren.
        </p>
        <figure>
            <img src="benutzer.png" alt="Liste aller Benutzer" />
            <figcaption>
                <strong>Abbildung 1</strong>: Liste der eingetragenen Benutzer <a href="#r13">[13]</a>.
            </figcaption>
        </figure>
        <p>
            Beim Teilen gibt es verschiedene Möglichkeiten dieses zu gestalten. Zum einen können Dateien mit ganzen
            Gruppen oder einzelnen Personen geteilt werden.
            Des Weiteren lassen sich Optionen wie „kann bearbeiten“, „aktualisieren“, „löschen“ und „teilen“ auswählen.
            Auch das Setzen eines Ablaufdatums ist möglich,
            sowie eine zusätzliche Mitteilung per Email mit der Information, dass etwas mit einem geteilt wurde. Aber
            auch das Teilen mit Dritten, die nicht zu den
            eingetragenen Benutzern gehören, ist möglich. Hierfür orientiert sich ownCloud an Dropbox oder auch Google,
            indem es den Link zum kopieren und weiterleiten gibt
            (siehe Abb 2).
        </p>
        <figure>
            <img src="shareoptions.png" alt="Teilen" />
            <figcaption>
                <strong>Abbildung 2</strong>: Optionen beim Teilen von Daten <a href="#r13">[13]</a>.
            </figcaption>
        </figure>
        <p>
            Gerade in Hinblick auf das Zusammenarbeiten und Teilen von Daten ist die Übersicht der neusten Aktivitäten
            sehr nützlich. Hier werden alle Aktivitäten, die
            einen selbst betreffen mit zusätzlichen Details angezeigt (siehe Abb.3).
        </p>
        <figure>
            <img src="activity_c.png" alt="Aktivitätsübersicht" />
            <figcaption>
                <strong>Abbildung 3</strong>: Übersicht der Aktivität <a href="#r13">[13]</a>.
            </figcaption>
        </figure>
    </section>
    <section>
        <h2>5. Fazit</h2>

        <p>
            Die Vorteile der Nutzung von Cloud Diensten liegt klar auf der Hand: Die Daten sind unabhängig von Standort
            und Gerät immer abrufbar. Im Falle eines
            Schadens an der Festplatte oder ähnlichem sind zudem diese Daten nicht verloren. Auch vereinfacht es
            Projektarbeiten. Doch es gibt immer zwei Seiten
            einer Medaille und so sollte sich jeder bewusst sein, dass wenn man seine Daten, seien es persönliche,
            geschäftliche, belanglose oder sensible Daten, online hochlädt und
            auf fremden Servern speichert, die theoretische Möglichkeit besteht, dass jemand Fremdes sich leichter und
            unter Umständen unbemerkt Zugriff zu diesen Daten beschaffen kann.
        </p>
        <p>
            Große Anbieter wie Dropbox und Google versprechen viel Leistung, gerade auch in Hinblick auf Sicherheit,
            aber so zeigte sich besonders im letzten Jahr wie
            viel hinter den Kulissen geschieht, ausgehend von der Politik und den Geheimdiensten, von dem Anwender
            nichts mitbekommen. Die besten
            Verschlüsselungsalgorithmen bei der Übertragung von Daten oder beim Ablegen der selbigen auf den Servern
            nützen nichts, wenn die Schlüssel von den Firmen
            selbst verwaltet werden und sie auf Verlangen der Regierung diese herausgeben müssen.
        </p>
        <p>
            Eine Alternative ist sicher die zusätzliche lokale Verschlüsselung, so wie sie Boxcryptor anbietet. Oder
            auch gänzlich auf das Zwischenspeichern auf
            Servern zu verzichten und Daten direkt zu Synchronisieren, so wie BitTorrent Sync es vorschlägt. Die Idee
            sich seine eigene Cloud aufzusetzen erscheint im
            ersten Moment auch eine interessante Alternative zu sein. Jedoch kann dieser Enthusiasmus schnell
            verfliegen, denn die Herausforderung diese so sicher wie
            möglich zu gestalten und den gleichen Service zu bieten wie die Vorbilder, ist doch größer als anfänglich
            gedacht. Viel Freiheit in Gestaltung und
            Umsetzung bedeutet in diesem Fall auch sehr viel Verantwortung, welche nur mit Grundkenntnissen kaum
            erfüllbar ist.
        </p>
    </section>
    <section class="references">
        <h2>6. Bibliography</h2>
        <p class="reference" id="r1">[1] H. Bu and K. Kuwabara, “Toward Crowdsourced Knowledge Graph Construction:
            Interleaving Collection and Verification of Triples,”in International Conference on Agents and Artificial
            Intelligence,Science and Technology Publications, Lda, 2022, pp. 375–382. doi: 10.5220/0010902700003116.</p>
        <p class="reference" id="r2">[2] A. Hogan et al., “Knowledge Graphs,” Sep. 2021, doi: 10.1145/3447772.</p>
        <p class="reference" id="r3">[3] D. Fensel et al., “Knowledge Graphs Methodology, Tools and Selected Use Cases.”
        </p>
        <p class="reference" id="r4">[4] ] E. B, “Data Solutions for Professional Services,” Engine B, Feb. 02, 2021. <a
                href="https://engineb.com/2021/02/8-key-benefits-of-knowledge-graphs/">https://engineb.com/2021/02/8-key-benefits-of-knowledge-graphs/</a>
            (30.06.2025)</p>
        <p class="reference" id="r5">[5]“In-depth Guide to Knowledge Graph: Benefits, Use Cases & Examples,”
            research.aimultiple.com.
            <a href="https://research.aimultiple.com/knowledge-graph/ ">https://research.aimultiple.com/knowledge-graph/
            </a> (30.06.2025)
        </p>
        <p class="reference" id="r6">[6] “What are the key benefits of using knowledge graphs?,” Zilliz.com, Dec. 09,
            2024. <a
                href="https://zilliz.com/ai-faq/what-are-the-key-benefits-of-using-knowledge-graphs">hhttps://zilliz.com/ai-faq/what-are-the-key-benefits-of-using-knowledge-graphs</a>
            (30.06.2025)</p>
        <p class="reference" id="r7">[7] B. Xue and L. Zou, “Knowledge Graph Quality Management: A Comprehensive
            Survey,” IEEE Trans Knowl Data Eng, vol. 35, no. 5, pp. 4969–4988, May 2023, doi: 10.1109/TKDE.2022.3150080.
        </p>
        <p class="reference" id="r8"> [8] S. Tsaneva, D. Dessì, F. Osborne, and M. Sabou, “Knowledge graph validation by
            integrating LLMs and human-in-the-loop,” 2025, doi: 10.5281/zenodo.13730203.</p>
        <p class="reference" id="r9"> [9] J. E. L. Gayo, A. Dimou, K. Thornton, and A. Rula, “Editorial of knowledge
            graphs validation and quality,” Sep. 26, 2022, IOS Press BV. doi: 10.3233/SW-223261.</p>
        <p class="reference" id="r10"> [10] L. Greif, S. Hauck, A. Kimmig, and J. Ovtcharova, “A Knowledge Graph
            Framework to Support Life Cycle Assessment for Sustainable Decision-Making,” Applied Sciences (Switzerland),
            vol. 15, no. 1, Jan. 2025, doi: 10.3390/app15010175.</p>
        <p class="reference" id="r11">[11] X. Wang et al., “Knowledge graph quality control: A survey,” Sep. 01, 2021,
            KeAi Communications Co. doi: 10.1016/j.fmre.2021.09.003.</p>
        <p class="reference" id="r12">[12] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, “Learning Entity and Relation
            Embeddings for Knowledge Graph Completion.” [Online]. Available: www.aaai.org </p>
        <p class="reference" id="r13"> [13] E. Huaman, E. Kärle, and D. Fensel, “Knowledge Graph Validation,” May 2020,
            [Online]. Available: http://arxiv.org/abs/2005.01389 </p>
        <p class="reference" id="r14"> [14] J. Gao, X. Li, Y. E. Xu, B. Sisman, X. L. Dong, and J. Yang, “Efficient
            knowledge graph accuracy evaluation,” in Proceedings of the VLDB Endowment, VLDB Endowment, 2018, pp.
            1679–1691. doi: 10.14778/3342263.3342642.</p>
        <p class="reference" id="r15"> [15] R.Y. Wang, D.M. Strong, Beyond accuracy: what data quality means to data
            consumers, J. Manag. Inf. Syst. 12 (4) (1996) 5–33.</p>
        <p class="reference" id="r16"> [16] F. Naumann, in: Quality-Driven Query Answering for Integrated Information
            Systems, 2261, Springer, 2003.</p>
        <p class="reference" id="r17"> [17] A. Zaveri, A. Rula, A. Maurino, R. Pietrobon, J. Lehmann, and S. Auer,
            “Quality assessment for Linked Data: A Survey,” in Semantic Web, IOS Press, 2016, pp. 63–93. doi:
            10.3233/SW-150175.</p>
        <p class="reference" id="r18"> [18] A. Revenko, A. Ahmeti, M. Schauer, and M. Sabou, “Crowd-sourced knowledge
            graph extension: a belief revision based approach.” [Online]. Available: www.w3.org/OWL </p>
        <p class="reference" id="r19"> [19] A. Oelen, M. Stocker, and S. Auer, “Creating and validating a scholarly
            knowledge graph using natural language processing and microtask crowdsourcing,” International Journal on
            Digital Libraries, vol. 25, no. 2, pp. 273–285, Jun. 2024, doi: 10.1007/s00799-023-00360-7.</p>
        <p class="reference" id="r20"> [20] L. Greif, S. Hauck, A. Kimmig, and J. Ovtcharova, “A Knowledge Graph
            Framework to Support Life Cycle Assessment for Sustainable Decision-Making,” Applied Sciences (Switzerland),
            vol. 15, no. 1, Jan. 2025, doi: 10.3390/app15010175. </p>
        <p class="reference" id="r21"> [21] Diplom-Ingenieurin, “Extraktionv on SHACLShapesfür Evolving KnowledgeGraphs
            DIPLOMARBEIT zur Erlangung des akademischen Grades.” doi: 10.34726/hss.2025.120502.</p>
        <p class="reference" id="r22"> [22] Holger Knublauch and Dimitris Kontokostas. 2017. Shapes Constraint Language
            (SHACL), W3C Recommendation 20 July 2017. W3C Recommendation. World Wide Web Consortium.
            <a href="https://www.w3.org/TR/2017/REC-shacl-20170720/ ">https://www.w3.org/TR/2017/REC-shacl-20170720/
            </a> (30.06.2025)
        </p>
        <p class="reference" id="r23"> [23] S. Tsaneva, D. Dessì, F. Osborne, and M. Sabou, “Knowledge graph validation
            by integrating LLMs and human-in-the-loop,” 2025, doi: 10.5281/zenodo.13730203.</p>
        <p class="reference" id="r24"> [24] B. Zhang, A. M. Peñuela, and E. Simperl, “Towards Explainable Automatic
            Knowledge Graph Construction with Human-in-the- Loop,” in Frontiers in Artificial Intelligence and
            Applications, IOS Press BV, Jun. 2023, pp. 274–289. doi: 10.3233/FAIA230091.</p>
        <p class="reference" id="r25"> [25] ]“Shapes Constraint Language (SHACL),” www.w3.org.
            <a href="https://www.w3.org/TR/shacl/ ">https://www.w3.org/TR/shacl/ </a> (30.06.2025)
        </p>

        </p>

    </section>
</body>

</html>